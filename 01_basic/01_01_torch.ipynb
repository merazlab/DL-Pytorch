{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_01_torch.ipynb","provenance":[],"collapsed_sections":["ykOoksQOxPkp","HOHkRq5f7m4w","Nz7Hx_2oCwiq","uK3qto4bF9Bf","inskClKqOyya"],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_s5fjoK5YpWj"},"source":["# Welcom to Torch library\n","\n","1.   Tensor\n","2.   ceation ops\n","3.   Indexing\n","4.   Random Samplig\n","\n","---\n"]},{"cell_type":"code","metadata":{"id":"mbPHiOTTZo7A"},"source":["#introduction to pytorch\n","#torch is a deep learning library that provide tensor data structure for GPU base computation.\n","import torch\n","print(torch.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R3oz4JqXZxNQ"},"source":["# numpy is python module that provide multidimensional arrays such as matrices along with various operation\n","# like transpose multipication inverse etc.\n","import numpy as np\n","print(np.version.version)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f4W7KzM8Z4pl"},"source":["#this function prints dimensions,shape,datatype,whether stored in GPU and class type  \n","def prop(t):\n","    print(\"dim->>{} : shape->>{} : dtype->>{} : GPU->>{} : Type-->{}\".format(t.ndim, t.shape, t.dtype, t.is_cuda, type(t)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nz1o9NAgbJqM"},"source":["# syntax for creating a variable through tensor\n","x = torch.tensor([5])\n","# prop() returns description of tensor as defined in above cell\n","prop(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YrRv5Hj0csUC"},"source":["## tensors"]},{"cell_type":"code","metadata":{"id":"1DEsR_XybWX-"},"source":["#syntax for creating an array through tensor\n","x = torch.tensor([1, 2, 3, 4])\n","# returns true if object is tensor type\n","print(torch.is_tensor(x))\n","x=[5]\n","print(torch.is_tensor(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iOfjzgMedJsg"},"source":["#returns true if object is pytorch storage object\n","torch.is_storage(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ktHhwjsUdRjR"},"source":["'''Returns True if the data type of input is a floating point data type i.e., one of torch.float64, torch.float32, torch.float16, and torch.bfloat16.'''\n","\n","x = torch.tensor([1.0, 2.0, 3.0, 4.0])\n","prop(x)\n","print(torch.is_floating_point(x))\n","# if input is not given in correct format default tensor convert to floating point type\n","x = torch.tensor([1.0, 2, 3.0, 4])\n","prop(x)\n","print(torch.is_floating_point(x))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60dWyTeTdkvq"},"source":["# if only integers are given in input then is_floating point return False\n","x = torch.tensor([1, 4])\n","prop(x)\n","torch.is_floating_point(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ftSD5yKQds1n"},"source":["# returns true if input is non zero and single element tensor\n","print(torch.is_nonzero(torch.tensor([0])))\n","print(torch.is_nonzero(torch.tensor([2])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4oYx7SB2esae"},"source":["# false because element of tensor is zero \n","torch.is_nonzero(torch.tensor([0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MO4gHiehewKn"},"source":["# also valid for floating point\n","torch.is_nonzero(torch.tensor([0.0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVwK8vHAe1YA"},"source":["# also works with boolean values\n","torch.is_nonzero(torch.tensor([True]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9fxwBRBke776"},"source":["# returns default data type of tensor\n","torch.tensor([2, 3.2]).dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AP1rNaTtffiP"},"source":["# set_default_dtype\n","# way to change default dtype of tensor\n","torch.set_default_dtype(torch.float64) #default is now changed to torch.float64\n","torch.tensor([2, 3.2]).dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fh3V-DEJfiw1"},"source":["torch.tensor([2, 5]).dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXT3JtasfnTT"},"source":["torch.tensor([3.2]).dtype"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rj-C2cU4fx93"},"source":["torch.get_default_dtype()  # initial default for floating point is torch.float32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QzW1bRO6iGNO"},"source":["# setting tensor type to its default original type\n","torch.set_default_tensor_type(torch.FloatTensor)  # setting tensor type also affects this"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dW62HJYCiUs4"},"source":["# getting default tensor type\n","torch.get_default_dtype()  # changed to torch.float32, the dtype for torch.FloatTensor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkEPeuu-ibUi"},"source":["#randn() return a tensor filled with random numbers from from normal distribution(mean=0 and variance=1) \n","a = torch.randn(1,2,3,4,5) #shape of tensor is decided by argument i.e giving n elements => n dimension\n","torch.numel(a) #returns total number of elements in input tensor"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QsW0oxHYi2Pu"},"source":["## creating ops"]},{"cell_type":"markdown","metadata":{"id":"xVgZDGo5jY_x"},"source":["\n","```\n","torch.tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) → Tensor\n","\n","data(array_like)\n","```"]},{"cell_type":"code","metadata":{"id":"5PZxhSgTilTv"},"source":["# creating a tensor through list\n","a = [0.5, 0.6]\n","x = torch.tensor(a)\n","prop(x)\n","# requires_grad is True if gradients need to be computed for this Tensor\n","# return false because default value of require_grad is false\n","x.requires_grad"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dMK8o740jmR7"},"source":["a = [1.0, 2.0]\n","#device option in tensor specifies the type of cuda device for tensors\n","y = torch.tensor(a, requires_grad=True, device=torch.device('cuda:0')) # check GPu must be enable\n","prop(y)\n","print(y.requires_grad)\n","y.device"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Yc4pSU-j_XO"},"source":["# ############################## doubt????\n","#torch.sparse_coo_tensor(indices, values, size=None, *, dtype=None, device=None, requires_grad=False) → Tensor\n","i = torch.tensor([[0, 1, 1],[2, 0, 2]])\n","v = torch.tensor([3, 4, 5], dtype=torch.float32)\n","a = torch.sparse_coo_tensor(i, v, [2, 4])\n","print(prop(i))\n","print(prop(v))\n","print(prop(a))\n","print(a)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_V3qYs7zppwj"},"source":["``` torch.as_tensor(data, dtype=None, device=None) → Tensor\n","Convert the data into a torch.Tensor. If the data is already a Tensor with\n","the same dtype and device, no copy will be performed, otherwise a new Tensor\n","will be returned with computational graph retained if data Tensor has\n","requires_grad=True. Similarly, if the data is an ndarray of the corresponding\n","dtype and the device is the cpu, no copy will be performed.```"]},{"cell_type":"code","metadata":{"id":"RY7ydXRJpiHz"},"source":["import numpy\n","a = numpy.array([1.0, 2.0, 3.0])\n","# converts data into torch tensor and stores on cpu\n","t = torch.as_tensor(a)\n","t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Cfd3_btqF_9"},"source":["# value of tensor is being changed \n","t[0] = 7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iOCwgCC6qInu"},"source":["# As dtype and device is same so they share same memory hence changes are reflecting\n","print(a)\n","print(t)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"obSAmUOUqJuZ"},"source":["a = numpy.array([1.0, 2.0, 3.0])\n","# tensor created on gpu\n","u = torch.as_tensor(a, device=torch.device('cuda:0'))\n","u"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zMLjNoN_qgua"},"source":["u[0]=8"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7VfYIZoqiXK"},"source":["# As dtype is same but device is different so changes will not reflect because they don't share same memory\n","print(a)\n","print(u)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yQWlHMH_rMBR"},"source":["from_numpy"]},{"cell_type":"code","metadata":{"id":"MWq3HUKyql_z"},"source":["b = numpy.array([1, 2, 3, 4, 5, 6])\n","# Another method for creating tensor and both share same memory\n","# changes made to any one of them will reflect in both of them\n","# through this method user defined customization is not possible regarding device and shape\n","# it is also not resizable\n","t = torch.from_numpy(b)\n","t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Di_2HSj7rPSn"},"source":["t[0] = 8\n","b[4] = 1\n","t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4wzzzP4urTG2"},"source":["b"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yn4P8MzgrUGX"},"source":["# shortcuts for creating user defined tensors\n","o = torch.ones((2, 3))\n","z = torch.zeros((3, 3))\n","# torch.empty(...) returns a tensor with uninitialised data\n","e = torch.empty((2, 4))\n","f = torch.full((3, 2), 9)\n","print(o)\n","print(z)\n","print(e)\n","print(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-QP_NC-UsFLY"},"source":["# some more shortcuts for creating default tensor\n","print(torch.ones_like(o))\n","print(torch.zeros_like(z))\n","print(torch.empty_like(e))\n","print(torch.full_like(e, 6))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QPKR2wgZvdtC"},"source":["arange"]},{"cell_type":"code","metadata":{"id":"KL19Ub5estnt"},"source":["## Note torch range is depresated\n","# returns 1-d tensor\n","print(torch.arange(5))\n","print(torch.arange(2, 6))\n","print(torch.arange(2, 10, 3))\n","t = torch.arange(1, 3, 0.5)\n","prop(t)\n","t"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wbrrw1HWvkr7"},"source":["linspace"]},{"cell_type":"code","metadata":{"id":"cR_FlZXZuHtL"},"source":["# Creates a one-dimensional tensor of size steps whose values are evenly spaced from start to end, inclusive.\n","print(torch.linspace(3, 10, steps=5))\n","print(torch.linspace(start=-10, end=10, steps=5))\n","print(torch.linspace(start=-10, end=10, steps=1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RBb_Jzzwvq6h"},"source":["logspace"]},{"cell_type":"code","metadata":{"id":"sSxe2NGVvs5H"},"source":["# creates a one-dimensional tensor of size steps whose values are evenly spaced from base**start to base**end,\n","# inclusive, on a logarithmic scale with base base\n","# default base is 10.0\n","print(torch.logspace(3, 10, steps=5))\n","print(torch.logspace(start=-10, end=10, steps=5))\n","print(torch.logspace(start=-10, end=10, steps=1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nY2XWPLjwQ0Z"},"source":["complex"]},{"cell_type":"code","metadata":{"id":"Df98uisHvzgt"},"source":["# creating a complex tensor with real and imaginay part\n","real = torch.tensor([1, 2], dtype=torch.float32)\n","imag = torch.tensor([3, 4], dtype=torch.float32)\n","z = torch.complex(real, imag)\n","z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GP98k3W0wUBU"},"source":["# dtype of a complex tensor\n","z.dtype"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eykJDR4SxeY5"},"source":["cartisian to polar"]},{"cell_type":"code","metadata":{"id":"RWYdHa9PwWp4"},"source":["# converting cartessian coordinate to polar coordinate using tensors\n","abs = torch.tensor([1, 2], dtype=torch.float64)\n","angle = torch.tensor([np.pi / 2, np.pi], dtype=torch.float64)\n","print(abs)\n","print(angle)\n","# create a complex tensor of type [abs*cos(angle)+abs*sin(angle)*j],where abs and angle as defined above.\n","z = torch.polar(abs, angle)\n","z"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ykOoksQOxPkp"},"source":["## Indexing, Slicing, Joining, Mutating Ops"]},{"cell_type":"markdown","metadata":{"id":"LvoYbhDgz03F"},"source":["cat or concat(alias of cat)\n","\n","``` \n","torch.cat(tensors, dim=0, *, out=None) → Tensor\n","can be seen as an inverse operation for torch.split() and torch.chunk().\n","```"]},{"cell_type":"code","metadata":{"id":"lObYNLxOwxu0"},"source":["a = torch.tensor(3)\n","b = torch.tensor(4)\n","prop(a)\n","prop(b)\n","torch.cat((a, b)) #any zero-dimensional tensor or more (at position 0) cannot be concatenated"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlHI80Q20bLQ"},"source":["a = torch.tensor(3)\n","b = torch.tensor([3])\n","prop(a)\n","prop(b)\n","torch.cat((a, b)) #zero-dimensional tensor (at position 0) cannot be concatenated"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AYPE9lLw1uWC"},"source":["a = torch.tensor([3])\n","b = torch.tensor([4])\n","prop(a)\n","print(torch.concat((a, b)))\n","print(torch.concat((a, b), dim=0))\n","# print(torch.concat((a, b), dim=1)) #shows error because only dim=0 exist\n","\n","a = torch.tensor([3, 4, 5])\n","b = torch.tensor([7, 8, 9])\n","print(torch.concat((a, b), dim=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KcZumVJ0181Z"},"source":["#dimension refers to indices\n","a = torch.tensor([[3, 4, 5]])\n","b = torch.tensor([[7, 8, 9]])\n","prop(a)\n","prop(b)\n","print(torch.concat((a, b), dim=0))\n","print(torch.concat((a, b), dim=1))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GCaCSsg3pSf"},"source":["a = torch.tensor([[1, 2, 3],\n","                  [3, 4, 5]])\n","b = torch.tensor([[7, 8, 9]])\n","prop(a)\n","prop(b)\n","print(torch.concat((a, b), dim=0))\n","print(torch.concat((a, b), dim=1)) # Show error because a dimension sizee not match with b dimension size "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BirTjCs04EBR"},"source":["a = torch.tensor([[1, 2, 3],\n","                  [3, 4, 5]])\n","# b = torch.tensor([[7, 8]])   b is 1 * 2 not match with  2 *3 dimension 1 and cause problem\n","b = torch.tensor([[7],\n","                  [8]])  \n","\n","prop(a)\n","prop(b)\n","\n","print(torch.concat((a, b), dim=1))  #All tensors must either have the same shape (except in the concatenating dimension) or be empty."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcuCdG3g4oEu"},"source":["a = torch.tensor([[1, 2, 3],\n","                  [3, 4, 5]])\n","b = torch.tensor([6, 7, 8])  \n","prop(a)\n","prop(b)\n","\n","print(torch.concat((a, b), dim=0))  # First check dimension then checks size"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PUud76wfAmQ7"},"source":["stack\n","```\n","Concatenates a sequence of tensors along a new dimension.\n","All tensors need to be of the same size.\n","\n","hstack\n","Stack tensors in sequence horizontally (column wise).\n","This is equivalent to concatenation along the first axis for 1-D tensors, along the second axis for all other tensors.\n","\n","vstack\n","Stack tensors in sequence vertically (row wise).\n","This is equivalent to concatenation along the **first axis** after all 1-D tensors have been reshaped by torch.atleast_2d().\n","```"]},{"cell_type":"code","metadata":{"id":"qovB6SCX_bI5"},"source":["a = torch.tensor([1, 2, 3])\n","b = torch.tensor([4, 5, 6])\n","prop(a)\n","prop(b)\n","# Stack tensors in sequence horizontally (column wise).\n","print(torch.hstack((a,b)))\n","\n","a = torch.tensor([[1],[2],[3]])\n","b = torch.tensor([[4],[5],[6]])\n","\n","prop(a)\n","prop(b)\n","# This is equivalent to concatenation along the first axis for 1-D tensors, and along the second axis for all other tensors.\n","print(torch.hstack((a,b)))\n","\n","a = torch.tensor([[[1, 2, 0],\n","                   [3, 4, 0]],\n","                  [[5, 6, 9],\n","                   [7, 8, 9]]])\n","\n","prop(a)\n","torch.hstack((a,a))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gry74vjtBnVu"},"source":["a = torch.tensor([1, 2, 3])\n","b = torch.tensor([4, 5, 6])\n","prop(a)\n","prop(b)\n","# Stack tensors in sequence vertically (row wise).\n","print(torch.vstack((a,b)))\n","\n","a = torch.tensor([[1],[2],[3]])\n","b = torch.tensor([[4],[5],[6]])\n","prop(a)\n","prop(b)\n","\n","print(torch.vstack((a,b)))\n","\n","a = torch.tensor([[[1, 2, 0],\n","                   [3, 4, 0]],\n","                  [[5, 6, 9],\n","                   [7, 8, 9]]])\n","\n","# prop(a)\n","torch.hstack((a,a))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"icjr9zTELHmY"},"source":["stack vs concat"]},{"cell_type":"code","metadata":{"id":"4nYjgUtULMEd"},"source":["t1 = torch.tensor([[1, 2],\n","                   [3, 4]])\n","\n","t2 = torch.tensor([[5, 6],\n","                   [7, 8]])\n","print(torch.stack((t1, t2))) # Concatenates a sequence of tensors along a new dimension and size must be same of all tensor\n","print(torch.concat((t1, t2), dim=0))\n","print(torch.concat((t1, t2), dim=1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6z5qt_fPQCQX"},"source":["Dstak\n","```\n","Stack tensors in sequence depthwise (along third axis).\n","This is equivalent to concatenation along the third axis after 1-D and 2-D tensors have been reshaped by torch.atleast_3d().\n","\n","columns_stack\n","Creates a new tensor by horizontally stacking the tensors in tensors.\n","Equivalent to torch.hstack(tensors), except each zero or one dimensional tensor t in tensors is first reshaped into a (t.numel(), 1) column before being stacked horizontally.\n","\n","row_stack\n","Alias of torch.vstack().\n","```"]},{"cell_type":"code","metadata":{"id":"wpXQg-UFPV_7"},"source":["a = torch.tensor([1, 2, 3])\n","b = torch.tensor([4, 5, 6])\n","prop(a)\n","prop(b)\n","# it first reshape 1-D and 2-D tensors to 3-D using torch.atleast_3d() ant then\n","# Stack tensors in sequence depthwise (along third axis)\n","print(torch.dstack((a,b)))\n","\n","a = torch.tensor([[1, 7],[2, 8],[3, 9]])\n","b = torch.tensor([[4, 1],[5, 1],[6, 1]])\n","prop(a)\n","prop(b)\n","print(torch.dstack((a,b)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PPTaZE69Japh"},"source":["a = torch.tensor([1, 2, 3])\n","b = torch.tensor([4, 5, 6])\n","# Creates a new tensor by horizontally stacking the tensors in tensors.\n","print(torch.column_stack((a, b)))\n","\n","a = torch.arange(5)\n","b = torch.arange(10).reshape(5, 2)\n","# Equivalent to torch.hstack(tensors), except each zero or one dimensional tensor t in tensors is first reshaped into a (t.numel(), 1) \n","# column before being stacked horizontally.\n","\n","print(torch.column_stack((a, b, b)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SeNOwhA5RikG"},"source":["```\n","torch.chunk(input, chunks, dim=0) → List of Tensors\n","Note\n","Attempts to split a tensor into the specified number of chunks. Each chunk is a view of the input tensor.\n","\n","torch.tensor_split() a function that always returns exactly the specified number of chunks\n","\n"]},{"cell_type":"code","metadata":{"id":"CtfJPAAOR6ov"},"source":["# Attempts to split a tensor into the specified number of chunks. Each chunk is a view of the input tensor.\n","# Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by chunks.\n","torch.arange(11).chunk(6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKUjaX7_SGId"},"source":["torch.arange(12).chunk(6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqI-OQiFSKrD"},"source":["# returnded 5 chunks because last chunk have to be smaller because tensor size is not divisible by chunks\n","# it can create less or equal nuber of chunks but not greater than specified number of chunks\n","torch.arange(13).chunk(6)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J-wpmDXOS7nD"},"source":["```\n","split\n","hsplit\n","vsplit\n","```\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"ZnVrENOrTIzL"},"source":["a = torch.arange(10).reshape(5,2)\n","print(a)\n","# Splits the tensor into chunks. Each chunk is a view of the original tensor.\n","# If split_size_or_sections is an integer type, then tensor will be split into equally sized chunks (if possible).\n","# Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by split_size.\n","print(torch.split(a, 2))\n","# If split_size_or_sections is a list, then tensor will be split into len(split_size_or_sections) chunks \n","# with sizes in dim according to split_size_or_sections.\n","print(torch.split(a, [1,4]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hs8UuBTdT6gt"},"source":["t = torch.arange(16.0).reshape(4,4)\n","print(t)\n","# Splits input, a tensor with one or more dimensions, into multiple tensors horizontally according to indices_or_sections.\n","# Each split is a view of input.\n","print(torch.hsplit(t, 2))\n","# If input is one dimensional this is equivalent to calling torch.tensor_split(input, indices_or_sections, dim=0) \n","# (the split dimension is zero),and if input has two or more dimensions \n","# it’s equivalent to calling torch.tensor_split(input, indices_or_sections, dim=1)\n","# except that if indices_or_sections is an integer it must evenly divide the split dimension or a runtime error will be thrown.\n","print(torch.hsplit(t, [3, 6]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jp3iP68UT97_"},"source":["t = torch.arange(16.0).reshape(4,4)\n","print(t)\n","# Splits input, a tensor with two or more dimensions, into multiple tensors vertically according to indices_or_sections.\n","# This is equivalent to calling torch.tensor_split(input, indices_or_sections, dim=0) (the split dimension is 0)\n","# except that if indices_or_sections is an integer it must evenly divide the split dimension or a runtime error will be thrown.\n","print(torch.vsplit(t, 2))\n","print(torch.vsplit(t, [3, 6]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uKUTSqPdUTQu"},"source":["gather\n","```\n","torch.gather(input, dim, index, *, sparse_grad=False, out=None) → Tensor\n","```\n","[link text](https://i.stack.imgur.com/ZnXZD.png)"]},{"cell_type":"code","metadata":{"id":"Tuk67aa-UWC1"},"source":["t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","# Gathers values along an axis specified by dim.\n","print(torch.gather(t, 1, torch.tensor([[0, 0], [1, 0]])))\n","print(torch.gather(t, 1, torch.tensor([[0, 1], [1, 0]])))\n","print(torch.gather(t, 1, torch.tensor([[1, 0], [0, 0]])))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0qWIBFyFZNUU"},"source":["```\n","squezze\n","dim (int, optional) – if given, the input will be squeezed only in this dimension\n","unsqezze\n","```"]},{"cell_type":"code","metadata":{"id":"7LcMFRLjYbXy"},"source":["x = torch.zeros(2, 1, 2, 1, 2,1)\n","print(x.size())\n","# Returns a tensor with all the dimensions of input of size 1 removed.\n","y = torch.squeeze(x)\n","print(y.size())\n","# squeeze(input, 0) leaves the tensor unchanged.\n","y = torch.squeeze(x, 0)\n","print(y.size())\n","# squeeze(input, 1) will remove first tensors with size 1\n","y = torch.squeeze(x, 1)\n","print(y.size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LX2OjbkZZWyU"},"source":["x = torch.tensor([1, 2, 3, 4])\n","# Returns a new tensor with a dimension of size one inserted at the specified position.\n","# A dim value within the range [-input.dim() - 1, input.dim() + 1) can be used. \n","# Negative dim will correspond to unsqueeze() applied at dim = dim + input.dim() + 1.\n","print(torch.unsqueeze(x, 0))\n","print(torch.unsqueeze(x, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9y892uasaY86"},"source":["where"]},{"cell_type":"code","metadata":{"id":"WsE9pYpYabFP"},"source":["# Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1\n","x = torch.randn(3, 2)\n","y = torch.ones(3, 2)\n","print(x)\n","# Return a tensor of elements selected from either x or y, depending on condition.\n","print(torch.where(x > 0, x, y))\n","x = torch.randn(2, 2, dtype=torch.double)\n","print(x)\n","print(torch.where(x > 0, x, 0.))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SvRthBNIbDPF"},"source":["unbind"]},{"cell_type":"code","metadata":{"id":"0nlH2UEmbCgF"},"source":["# Removes a tensor dimension.\n","# default value of dim=0\n","# Returns a tuple of all slices along a given dimension, already without it.\n","t = torch.unbind(torch.tensor([[1, 2, 3],\n","                           [4, 5, 6],\n","                           [7, 8, 9]]))\n","print(t)\n","type(t)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IjYcKpTib1t-"},"source":["nonzero"]},{"cell_type":"code","metadata":{"id":"iaPGCKTbb3zI"},"source":["#  when default as_tuple=False returns a 2-D tensor where each row is the index for a nonzero value.\n","print(torch.nonzero(torch.tensor([1, 1, 1, 0, 1])))\n","\n","print(torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],\n","                            [0.0, 0.4, 0.0, 0.0],\n","                            [0.0, 0.0, 1.2, 0.0],\n","                            [0.0, 0.0, 0.0,-0.4]])) )\n","# when as_tuple =True\n","# Returns a tuple of 1-D tensors, one for each dimension in input, \n","# each containing the indices (in that dimension) of all non-zero elements of input .\n","\n","print(torch.nonzero(torch.tensor([1, 1, 1, 0, 1]), as_tuple=True))\n","\n","print(torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],\n","                            [0.0, 0.4, 0.0, 0.0],\n","                            [0.0, 0.0, 1.2, 0.0],\n","                            [0.0, 0.0, 0.0,-0.4]]), as_tuple=True) )\n","print(torch.nonzero(torch.tensor(5), as_tuple=True))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v_zfKsesjK6F"},"source":["```\n","- t\n","- transpose\n","- view\n","- reshape\n","- permute\n","\n","only for <=2d\n","```[link text](https://)\n"]},{"cell_type":"code","metadata":{"id":"8mmSV6AbjlB-"},"source":["x = torch.randn(())\n","print(x)\n","# torch.t() performs transpose operation of matrices of 2 or more dimension.\n","print(torch.t(x))\n","\n","x = torch.randn(3)\n","print(x)\n","print(torch.t(x))\n","\n","x = torch.randn(2, 3)\n","print(x)\n","print(torch.t(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uvyhjn14t3k4"},"source":["x = torch.randn(2, 3)\n","print(x)\n","# transpose(input,0,1) is equivalent to torch.t(input)\n","t = torch.transpose(x, 0, 1)\n","print(t.shape)\n","print(t)\n","print(torch.t(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFuTydGWuOZy"},"source":["# tensor.is_contigous() returns True if self tensor(i.e x or t) is contiguous in memory in the order specified by memory format.\n","# default memory format is torch.contiguous_format.\n","x = torch.randn(2, 3, 4)\n","print(x)\n","print(x.is_contiguous())\n","t = torch.transpose(x, 0, 1)\n","print(t.shape)\n","print(t.is_contiguous())\n","print(t)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MT5zhoJio7cl"},"source":["\"\"\"\n","view   vs reshape\n","\n","-The view() has existed for a long time. It will return a tensor with the new shape.\n","\"\"\"\n","# Returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1)\n","a = torch.rand(1, 4)\n","print(a)\n","# id(obj)-> This function takes an argument an object and returns a unique integer number which represents identity.\n","######## doubt-> regarding storage\n","print(id(a), id(a.storage()))\n","######## doubt -> working of view\n","b = a.view(2, 2)\n","print(b.is_contiguous())\n","print(id(b), id(b.storage())) # both a, b storage is same. View operation is contigious but transpose is not contigious \n","print(b)\n","# b and a share same memory\n","b[0][0] = 0.333\n","print(b)\n","print(a)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pPnW9e0AxGyu"},"source":["```\n","permute\n","permute() and tranpose() are similar. transpose() can only swap two dimension. But permute() can swap all the dimensions. For example:\n","```"]},{"cell_type":"code","metadata":{"id":"YKEw_Rv9ltRo"},"source":["x = torch.randn(2, 3, 5)\n","print(x)\n","x.size()\n","# Returns a view of the original tensor input with its dimensions permuted.\n","y=torch.permute(x, (2, 0, 1))\n","print(y.size())\n","print(y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wZTw6EhOxE8K"},"source":["reshape\n","\n","If you just want to reshape tensors, use torch.reshape. If you're also concerned about memory usage and want to ensure that the two tensors share the same data, use torch.view.\n","```\n","It means that torch.reshape may return a copy or a view of the original tensor. You can not count on that to return a view or a copy. According to the developer:\n","\n","Another difference is that reshape() can operate on both contiguous and non-contiguous tensor while view() can only operate on contiguous tensor.\n","```"]},{"cell_type":"code","metadata":{"id":"6SnwOQDfx_p0"},"source":["a = torch.rand(1, 4)\n","print(a)\n","print(id(a), id(a.storage()))\n","\n","b = a.view(2, 2)\n","print(b.is_contiguous())\n","print(id(b), id(b.storage())) \n","print(b)\n","\n","c = a.reshape(2, 2)  # more powerfull than view\n","print(c.is_contiguous())\n","print(id(c), id(c.storage())) \n","print(c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ydO0kKh90mtL"},"source":["```\n","swapaxes\n","swapdims\n","both are alis of torch.transpose()\n","```"]},{"cell_type":"markdown","metadata":{"id":"HFZzn-oV0_dx"},"source":["```\n","movedim\n","torch.movedim(input, source, destination) → Tensor\n","\n","moveaxis - is a equvalent of movedim\n","```"]},{"cell_type":"code","metadata":{"id":"tPb8Y71f0laN"},"source":["t = torch.randn(3,2,1)\n","print(t.shape)\n","print(t)\n","\n","print(torch.movedim(t, 1, 0).shape)\n","print(torch.movedim(t, 1, 0))\n","\n","print(torch.movedim(t, (1, 2), (0, 1)).shape)\n","print(torch.movedim(t, (1, 2), (0, 1)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HOHkRq5f7m4w"},"source":["## Random sampling\n"]},{"cell_type":"code","metadata":{"id":"MWyPtFZD8w3r"},"source":["t = torch.randint(low=0, high=7,size=(2, 1))\n","t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kFCSoSw-lEq"},"source":["torch.seed()  # For random number genration\n","t = torch.randint(low=0, high=7,size=(2, 1))\n","t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i3p9Q_Xn9e_H"},"source":["torch.manual_seed(0) # For random number genration for both cpu and gpu\n","t = torch.randint(low=0, high=7,size=(2, 1))\n","t"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jh1aVJgrANRp"},"source":["print(torch.rand(4))    #uniform distribution\n","print(torch.randn(4))   #Normal distribution\n","print(torch.randint(1, 5, (3,))) #uniform distribution\n","print(torch.randint(1, 5, (2, 3))) #uniform distribution\n","\n","# torch.rand_like\n","# torch.randn_like\n","# torch.randint_like"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z06vAxiLCAKC"},"source":["permutation"]},{"cell_type":"code","metadata":{"id":"2XZCa_a7B_Ao"},"source":["print(torch.randperm(4))\n","print(torch.randperm(4))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nz7Hx_2oCwiq"},"source":["## Save , Load"]},{"cell_type":"markdown","metadata":{"id":"dJPOfeQeDRaC"},"source":["```\n","torch.save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\n","\n","default file format is--->> .pt\n","```"]},{"cell_type":"code","metadata":{"id":"VPxONtt1C1np"},"source":["# Save to file\n","x = torch.tensor([0, 1, 2, 3, 4])\n","torch.save(x, 'tensor.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVtwFAvAEDNr"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbeFG5RLEJhe"},"source":["y = torch.load('tensor.pt')\n","prop(y)\n","y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgB03qPqEp5s"},"source":["y = torch.load('tensor.pt', map_location=torch.device('cpu'))\n","prop(y)\n","y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8OnUsGZFUKd"},"source":["y = torch.load('tensor.pt', map_location=torch.device('cuda'))\n","prop(y)\n","y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-DG61J0HFBEt"},"source":["y = torch.load('tensor.pt', map_location=lambda storage, loc: storage.cuda(0))\n","prop(y)\n","y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uK3qto4bF9Bf"},"source":["## Locally disabling gradient computation\n"]},{"cell_type":"code","metadata":{"id":"Pb-Md90sGCVJ"},"source":["x = torch.zeros(1, requires_grad=True)\n","with torch.no_grad():\n","    y = x * 2\n","print(y.requires_grad)\n","\n","is_train = False\n","with torch.set_grad_enabled(is_train):\n","    y = x * 2\n","print(y.requires_grad)\n","\n","torch.set_grad_enabled(True)  # this can also be used as a function\n","y = x * 2\n","print(y.requires_grad)\n","\n","torch.set_grad_enabled(False)\n","y = x * 2\n","print(y.requires_grad)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"inskClKqOyya"},"source":["## Other operation"]},{"cell_type":"markdown","metadata":{"id":"LflR8-I9PJOO"},"source":["atleast_1d\n","```\n","Returns a 1-dimensional view of each input tensor with zero dimensions. Input tensors with one or more dimensions are returned as-is.\n","```"]},{"cell_type":"code","metadata":{"id":"6khfR9x_RE3j"},"source":["t_0d = torch.tensor(5)\n","t_1d = torch.tensor([5, 6])\n","t_2d = torch.tensor([[5, 6], [7, 8]])\n","\n","print(torch.atleast_1d(t_0d))\n","print(torch.atleast_1d(t_1d))\n","print(torch.atleast_1d(t_2d))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yi-ODNGcP9MU"},"source":["t_0d = torch.tensor(5)\n","t_1d = torch.tensor([5, 6])\n","t_2d = torch.tensor([[5, 6], [7, 8]])\n","\n","print(torch.atleast_2d(t_0d))\n","print(torch.atleast_2d(t_1d))\n","print(torch.atleast_2d(t_2d))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9q01QH0QOGL"},"source":["t_0d = torch.tensor(5)\n","t_1d = torch.tensor([5, 6])\n","t_2d = torch.tensor([[5, 6], [7, 8]])\n","t_3d = torch.tensor([[[5, 6]],\n","                     [[7, 8]]])\n","\n","\n","print(torch.atleast_3d(t_0d))\n","print(torch.atleast_3d(t_1d))\n","print(torch.atleast_3d(t_2d))\n","print(torch.atleast_3d(t_3d))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H8Y_45dMQnde"},"source":[""],"execution_count":null,"outputs":[]}]}